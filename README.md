<div align="center">

# Predictive Manintenance: Anormaly Detection for CPE Replacement


<a href="https://pytorch.org/get-started/locally/"><img alt="Python" src="https://img.shields.io/badge/-Python 3.7--3.9-blue?style=for-the-badge&logo=python&logoColor=white"></a>
<a href="https://pytorch.org/get-started/locally/"><img alt="PyTorch" src="https://img.shields.io/badge/-PyTorch 1.8+-ee4c2c?style=for-the-badge&logo=pytorch&logoColor=white"></a>
<a href="https://pytorchlightning.ai/"><img alt="Lightning" src="https://img.shields.io/badge/-Lightning-792ee5?style=for-the-badge&logo=pytorchlightning&logoColor=white"></a>

<a href="https://hydra.cc/"><img alt="Config: hydra" src="https://img.shields.io/badge/config-hydra-89b8cd?style=for-the-badge&labelColor=gray"></a>
<a href="https://black.readthedocs.io/en/stable/"><img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-black.svg?style=for-the-badge&labelColor=gray"></a>



</div>
<br><br>



## ðŸ“Œ&nbsp;&nbsp;Introduction
This Project is focus on anormaly detection for DLS lines and CPE failure.

> Effective usage of this project requires learning of a couple of technologies: [PyTorch](https://pytorch.org), [PyTorch Lightning](https://www.pytorchlightning.ai) and [Hydra](https://hydra.cc). Knowledge of some experiment logging framework like [Weights&Biases](https://wandb.com), [Neptune](https://neptune.ai) or [MLFlow](https://mlflow.org) is also recommended.


### Why PyTorch Lightning?
[PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning) is a lightweight PyTorch wrapper for high-performance AI research.
It makes your code neatly organized and provides lots of useful features, like ability to run model on CPU, GPU, multi-GPU cluster and TPU.


### Why Hydra?
[Hydra](https://github.com/facebookresearch/hydra) is an open-source Python framework that simplifies the development of research and other complex applications. The key feature is the ability to dynamically create a hierarchical configuration by composition and override it through config files and the command line. It  allows you to conveniently manage experiments and provides many useful plugins, like [Optuna Sweeper](https://hydra.cc/docs/next/plugins/optuna_sweeper) for hyperparameter search, or [Ray Launcher](https://hydra.cc/docs/next/plugins/ray_launcher) for running jobs on a cluster.
<br>
<br>
<br>


## Additional Features
- **Predefined Structure**: clean and scalable so that work can easily be extended and replicated 
- **Rapid Experimentation**: thanks to automating pipeline with config files and hydra command line superpowers 
- **Little Boilerplate**: so pipeline can be easily modified 
- **Main Configuration**: main config file specifies default training configuration 
- **Experiment Configurations**: stored in a separate folder, they can be composed out of smaller configs, override chosen parameters or define everything from scratch 
- **Workflow**: comes down to 4 simple steps 
- **Experiment Tracking**: many logging frameworks can be easily integrated! 
- **Logs**: all logs (checkpoints, data from loggers, chosen hparams, etc.) are stored in a convenient folder structure imposed by Hydra 
- **Hyperparameter Search**: made easier with Hydra built in plugins like [Optuna Sweeper](https://hydra.cc/docs/next/plugins/optuna_sweeper) 
- **Tests**: unit tests and smoke tests 
- **Extra Features**: optional utilities to make your life easier
- **Best Practices**: a couple of recommended tools, practices and standards for efficient workflow and reproducibility 
<br>


## Project Structure
The directory structure of new project looks like this:
```
â”œâ”€â”€ configs                 <- Hydra configuration files
â”‚   â”œâ”€â”€ callbacks               <- Callbacks configs
â”‚   â”œâ”€â”€ datamodule              <- Datamodule configs
â”‚   â”œâ”€â”€ experiment              <- Experiment configs
â”‚   â”œâ”€â”€ hparams_search          <- Hyperparameter search configs
â”‚   â”œâ”€â”€ hydra                   <- Hydra related configs
â”‚   â”œâ”€â”€ logger                  <- Logger configs
â”‚   â”œâ”€â”€ model                   <- Model configs
â”‚   â”œâ”€â”€ trainer                 <- Trainer configs
â”‚   â”‚
â”‚   â””â”€â”€ config.yaml             <- Main project configuration file
â”‚
â”œâ”€â”€ data                    <- Project data
â”‚
â”œâ”€â”€ logs                    <- Logs generated by Hydra and PyTorch Lightning loggers
â”‚
â”œâ”€â”€ notebooks               <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                              the creator's initials, and a short `-` delimited description, e.g.
â”‚                              `1.0-jqp-initial-data-exploration.ipynb`.
â”‚
â”œâ”€â”€ tests                   <- Tests of any kind
â”‚   â”œâ”€â”€ smoke
â”‚   â””â”€â”€ unit
â”‚
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ callbacks               <- Lightning callbacks
â”‚   â”œâ”€â”€ datamodules             <- Lightning datamodules
â”‚   â”œâ”€â”€ models                  <- Lightning models
â”‚   â”œâ”€â”€ utils                   <- Utility scripts
â”‚   â”‚
â”‚   â””â”€â”€ train.py                <- Training pipeline
â”‚
â”œâ”€â”€ run.py                  <- Run any pipeline with chosen experiment configuration
â”‚
â”œâ”€â”€ .env.example            <- Template of the file for storing private environment variables
â”œâ”€â”€ .gitignore              <- List of files/folders ignored by git
â”œâ”€â”€ .pre-commit-config.yaml <- Configuration of automatic code formatting
â”œâ”€â”€ conda_env_gpu.yaml      <- File for installing conda environment
â”œâ”€â”€ Dockerfile              <- File for building docker container
â”œâ”€â”€ requirements.txt        <- File for installing python dependencies
â”œâ”€â”€ setup.cgf               <- Configurations of linters and pytest
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```
<br>
