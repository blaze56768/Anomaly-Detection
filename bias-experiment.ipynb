{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54df1b07-e352-40c1-a34f-4758055a1d62",
   "metadata": {},
   "source": [
    "# Bias Experiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3de66a-6593-4e06-a3ee-f3ad60225654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Science Packages\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import copy\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Seaborn Style\n",
    "sns.set(style='ticks')\n",
    "sns.set_style({'font.family': 'Hiragino Maru Gothic Pro'})\n",
    "sns.set_palette(\"cool\")\n",
    "\n",
    "# Pandas Style\n",
    "pd.set_option(\"display.max_column\", 9999)\n",
    "pd.set_option(\"display.max_row\", 9999)\n",
    "\n",
    "# Ignore annoying warning \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pytoch \n",
    "import torch\n",
    "\n",
    "# custom packages\n",
    "from src.datamodules.replacement_datamodule import ReplacementDataModule\n",
    "from src.models.convolutional_autoencoder import ConvNetAutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493d805-f057-41e9-a04e-9bf4eb56bcb4",
   "metadata": {},
   "source": [
    "# Defining general model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ad04d-a31a-4c57-bd54-50f3063819ec",
   "metadata": {},
   "source": [
    "In this secction we are going to define the general model. This model is the pretrain model that later is fine tune per class (eg, `thermal-damage`, `no-hardware-issue`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59a1c80-152e-47c8-b6ba-d37fe24a514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "hparams = OmegaConf.load('configs/model/conv-autoenc.yaml')\n",
    "autoencoder = ConvNetAutoEncoder(lr = hparams.lr,\n",
    "                                     latent_dim= hparams.latent_dim,\n",
    "                                     series_dim= hparams.series_dim,\n",
    "                                     features_dim= hparams.features_dim,\n",
    "                                     num_category= hparams.num_category,\n",
    "                                     num_numerical= hparams.num_numerical,\n",
    "                                     #categorical_weight_loss = hparams.categorical_weight_loss,\n",
    "                                     #numerical_weight_loss = hparams.numerical_weight_loss,\n",
    "                                     num_conv_blocks= hparams.num_conv_blocks,\n",
    "                                     dims_expand= hparams.dims_expand,\n",
    "                                     dropout_prob= hparams.dropout_prob,\n",
    "                                     weight_decay= hparams.weight_decay,\n",
    "                                     inter_dim= hparams.inter_dim)\n",
    "                                     #freeze_encoder = hparams.freeze_encoder,\n",
    "                                     #checkpoint = hparams.checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e8449-1d24-4c3e-bed3-2f5a6f77f153",
   "metadata": {},
   "source": [
    "# Loading checkpoint autoencoder: `thermal-damage`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7237f2ad-500e-4f74-9a46-e99cb7cbc653",
   "metadata": {},
   "source": [
    "Here we are going to load the weights for the autoencoder especialized in `thermal-damage`. Additionaly, we are going setup the model in evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b863564-9a97-4e81-98e9-375f39f9386d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetAutoEncoderBias(\n",
       "  (encoder): ConvEncoder(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (convblocks): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (conv1d): Conv1d(160, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batchnorm1d): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1d): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batchnorm1d): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=5120, out_features=250, bias=True)\n",
       "  )\n",
       "  (decoder): ConvDecoder(\n",
       "    (inverse_convblocks): ModuleList(\n",
       "      (0): InverseConvBlock(\n",
       "        (conv1d_trans): ConvTranspose1d(640, 320, kernel_size=(2,), stride=(2,))\n",
       "        (batchnorm1d): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InverseConvBlock(\n",
       "        (conv1d_trans): ConvTranspose1d(320, 160, kernel_size=(2,), stride=(2,))\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=250, out_features=5120, bias=True)\n",
       "  )\n",
       "  (criterion_mse): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_thermal = copy.deepcopy(autoencoder) #copy base model\n",
    "checkpoint = torch.load(\"logs/runs/convolutional-autoencoder-bias-thermal-damage/2021-09-17/10-12-14/checkpoints/epoch=102.ckpt\")\n",
    "autoencoder_thermal.load_state_dict(checkpoint['state_dict'])\n",
    "autoencoder_thermal.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeea88f0-9390-4ea7-a0a1-532351453e09",
   "metadata": {},
   "source": [
    "# Loading AutoEncoder for W724Ci family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f9ab58f-a5fa-4f83-9748-525fa5dd17ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetAutoEncoder(\n",
       "  (encoder): ConvEncoder(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (convblocks): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (conv1d): Conv1d(160, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batchnorm1d): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1d): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batchnorm1d): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (linear_2): Linear(in_features=5120, out_features=1024, bias=True)\n",
       "    (linear): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): ConvDecoder(\n",
       "    (inverse_convblocks): ModuleList(\n",
       "      (0): InverseConvBlock(\n",
       "        (conv1d_trans): ConvTranspose1d(640, 320, kernel_size=(2,), stride=(2,))\n",
       "        (batchnorm1d): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InverseConvBlock(\n",
       "        (conv1d_trans): ConvTranspose1d(320, 160, kernel_size=(2,), stride=(2,))\n",
       "      )\n",
       "    )\n",
       "    (linear_2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (linear): Linear(in_features=1024, out_features=5120, bias=True)\n",
       "  )\n",
       "  (criterion_mse): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_w724 = copy.deepcopy(autoencoder) #copy base model\n",
    "checkpoint = torch.load(\"logs/runs/convolutional-autoencoder/2021-09-28/10-57-37/checkpoints/epoch=85.ckpt\")\n",
    "autoencoder_w724.load_state_dict(checkpoint['state_dict'])\n",
    "autoencoder_w724.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18007909-02a0-4d0d-908f-3513cc205d93",
   "metadata": {},
   "source": [
    "# Define Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a03f6b-60d8-46f9-8374-72f5bb731c13",
   "metadata": {},
   "source": [
    "Here we are going to define the data loader. In the Notebook always `num_workers` must be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c5bfff5-fec8-4082-bdc7-1ea4c32b877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_datamodule = OmegaConf.load(\"configs/datamodule/cpe-replacement.yaml\")\n",
    "datamodule = ReplacementDataModule(data_dir = \"data/preprocessed/data_w32_g3/Family-All/maxmin\",\n",
    "                                     train_val_split = 0.9,\n",
    "                                     batch_size = 5000000,# Loss comparisson chancge teh BS to 5000000\n",
    "                                     num_workers = 0,\n",
    "                                     pin_memory = False,\n",
    "                                     features_dim = 160,\n",
    "                                     series_dim = 32,\n",
    "                                     name_labels = [\"label_minor_physical_thermal_damage\"],\n",
    "                                     sampler=True,\n",
    "                                     weights_minority_class = 8,\n",
    "                                     features_numerical= hparams_datamodule.features_numerical,\n",
    "                                     features_categorical= hparams_datamodule.features_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc0c96-f364-4efe-a901-63514e4ac9d7",
   "metadata": {},
   "source": [
    "Now we are just to init the test stage of the datamodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54090ff2-6bdf-41be-ba71-e9dbdb007a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples weights for Balance Random Sampler: \n",
      "    synthetic_class  indices    weights\n",
      "0              0.0     6219   1.049043\n",
      "1              1.0      305  21.390164\n",
      "Samples weights for Custom Random Sampler: \n",
      "    synthetic_class  weights\n",
      "0              0.0      1.0\n",
      "1              1.0      8.0\n"
     ]
    }
   ],
   "source": [
    "datamodule.setup(stage='fit')\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "val_dataloader = datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313dcd57-8850-46a2-a436-8ea1891d19dc",
   "metadata": {},
   "source": [
    "And we can access to a batch in the data set as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e3b1a8-2b23-4d37-abed-2cd8ef521c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_dataloader)\n",
    "input, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c79aba-0454-4f84-b1e7-d8022145e44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6524, 32, 160])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b413abc3-6537-49cd-9cbb-901f8d721fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6524, 32, 160])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_w724(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80d58a-de4f-4160-87cf-57040270537c",
   "metadata": {},
   "source": [
    "# Approach 1: Compare only the reconsturction loss of `cpe_type_W724Ci`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c9a4b4-cde8-42ff-aaae-2cc40ccec6b7",
   "metadata": {},
   "source": [
    "The only thing we need to compres is the input with the reconstruction and visualized the losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e509a81b-6a70-4485-92c1-12b5979b7e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_mse = torch.nn.MSELoss(reduce=False)\n",
    "reconstruction = autoencoder_w724(input)\n",
    "mse_loss =criterion_mse(reconstruction,input).mean(dim=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc89c242-b76b-4e2a-90a5-cc277978377f",
   "metadata": {},
   "source": [
    "Now we can compare the reconstruction loss with a threshold to obtain the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88b34ed0-52b3-4580-8750-ba14032520be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0003, 0.0007, 0.0008,  ..., 0.0005, 0.0012, 0.0019],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c6c4946-c7c0-4235-b329-b14da27585d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6524])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "213663a3-a84c-42d9-8ee9-0e5b9252affe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dc208f7-d6bc-4cf8-9491-d43e89c8292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0216, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26982135-9ff9-4cc3-af54-85d70caa36d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0013, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c400026-0c1b-4eb0-9a40-b58d86e1491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold =  0.0013\n",
    "preds = (mse_loss < threshold).float() * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4892b-fea3-4784-84c2-bb250fa8bc71",
   "metadata": {},
   "source": [
    "Here is the classification report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e97d72a2-8aca-43cc-a506-dcf06b17ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.42      0.57      4625\n",
      "         1.0       0.38      0.85      0.52      1899\n",
      "\n",
      "    accuracy                           0.55      6524\n",
      "   macro avg       0.63      0.64      0.55      6524\n",
      "weighted avg       0.73      0.55      0.56      6524\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/29 14:29:56 WARN TransportChannelHandler: Exception in connection from /192.168.0.101:56165\n",
      "java.io.IOException: Operation timed out\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:378)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1925d675-6e72-494d-b3c8-052adb2dbc8e",
   "metadata": {},
   "source": [
    "# Approach 2: Siamese Network Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab5862-8c3c-447e-9f3c-6760c88edb53",
   "metadata": {},
   "source": [
    "In the previous approach can be difficul for the model to compare just againt a threshold due to the fact that a sample can be just hard to reconstruct independly of the class. Therefore, in this seccion we are going to use a Siamese Network one finetune on `themal-damage` and the other one `all classes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60b71652-0592-41a1-9aea-bbdbcac3c029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetAutoEncoderBias(\n",
       "  (encoder): ConvEncoder(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (convblocks): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (conv1d): Conv1d(160, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batchnorm1d): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1d): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batchnorm1d): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=5120, out_features=250, bias=True)\n",
       "  )\n",
       "  (decoder): ConvDecoder(\n",
       "    (inverse_convblocks): ModuleList(\n",
       "      (0): InverseConvBlock(\n",
       "        (conv1d_trans): ConvTranspose1d(640, 320, kernel_size=(2,), stride=(2,))\n",
       "        (batchnorm1d): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InverseConvBlock(\n",
       "        (conv1d_trans): ConvTranspose1d(320, 160, kernel_size=(2,), stride=(2,))\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=250, out_features=5120, bias=True)\n",
       "  )\n",
       "  (criterion_mse): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_base = copy.deepcopy(autoencoder) #copy base model\n",
    "checkpoint = torch.load(\"logs/runs/convolutional-autoencoder-bias-no-problem/2021-09-17/16-54-44/checkpoints/epoch=116.ckpt\")\n",
    "autoencoder_base.load_state_dict(checkpoint['state_dict'])\n",
    "autoencoder_base.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52d07f8a-f65c-45b1-863b-47e02de237af",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_mse = torch.nn.MSELoss(reduce=False)\n",
    "\n",
    "# Thermal damage\n",
    "reconstruction = autoencoder_thermal(input)\n",
    "mse_loss_thermal =criterion_mse(reconstruction,input).mean(dim=(1,2))\n",
    "\n",
    "# Base\n",
    "reconstruction = autoencoder_base(input)\n",
    "mse_loss_base =criterion_mse(reconstruction,input).mean(dim=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbfba011-fe84-45cb-aa27-4c7e4ff3b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_thermal = 0.013\n",
    "preds_thermal = (threshold_thermal > mse_loss_thermal).float() * 1#\n",
    "preds_thermal[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "247d14b4-dc27-46ef-bed5-cac1e19c7a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_noissue = 0.00001\n",
    "preds_hard = (threshold_noissue < mse_loss_thermal).float() * 1\n",
    "preds_hard[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0504496-3c7d-4a72-9efb-6d47e301a72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds_hard*preds_thermal)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef35eabf-296d-4dfa-b8c1-595f7e7b4716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.83      0.90      2060\n",
      "         1.0       0.43      0.89      0.58       305\n",
      "\n",
      "    accuracy                           0.83      2365\n",
      "   macro avg       0.71      0.86      0.74      2365\n",
      "weighted avg       0.91      0.83      0.86      2365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds_hard*preds_thermal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafc54d-a920-474a-9b8c-372cc98f5dd9",
   "metadata": {},
   "source": [
    "# Approach 3: Siamese Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b221e1be-25e6-4ae3-8e22-5dc68e7cdcf0",
   "metadata": {},
   "source": [
    "In this section we are going to use 2 embedding (general and  themal damage) as feature extactor to traing a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e888ba87-a177-4d4c-8314-fdca2b28635c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder_thermal = copy.deepcopy(autoencoder) #copy base model\n",
    "checkpoint = torch.load(\"logs/runs/convolutional-autoencoder-bias-thermal-damage/2021-09-17/10-12-14/checkpoints/epoch=102.ckpt\")\n",
    "autoencoder_thermal.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "autoencoder_base = copy.deepcopy(autoencoder) #copy base model\n",
    "checkpoint = torch.load(\"logs/runs/convolutional-autoencoder/2021-09-17/01-26-12/checkpoints/epoch=40.ckpt\")\n",
    "autoencoder_base.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "autoencoder_noissue = copy.deepcopy(autoencoder) #copy base model\n",
    "checkpoint = torch.load(\"logs/runs/convolutional-autoencoder-bias-no-problem/2021-09-17/16-54-44/checkpoints/epoch=116.ckpt\")\n",
    "autoencoder_noissue.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121511f1-4b4d-4d21-93a1-d7f7d8840c96",
   "metadata": {},
   "source": [
    "Let froze the paramaters and define the encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66262700-4a32-4853-9ddf-9624e9759392",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_thermal.freeze()\n",
    "encoder_thermal = autoencoder_thermal.encoder\n",
    "\n",
    "#autoencoder_base.freeze()\n",
    "encoder_base = autoencoder_base.encoder\n",
    "\n",
    "autoencoder_noissue.freeze()\n",
    "encoder_noissue = autoencoder_noissue.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89863f5b-d52c-4807-9c9c-ec62fb40564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "\n",
    "class SiameseClassifier(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Convolutional Autoencoder.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 lr = 0.0003,\n",
    "                 dropout_prob= 0.25,\n",
    "                 weight_decay= 0.05,\n",
    "                 latent_dim = 750,\n",
    "                 inter_dim = 64,\n",
    "                 output_dim = 1,\n",
    "                 freeze_encoder = True,\n",
    "                 encoder_thermal= autoencoder_thermal,\n",
    "                 encoder_base= autoencoder_base,\n",
    "                 name_labels_logger=['label_minor_physical_thermal_damage'],\n",
    "                 **kwargs):\n",
    "       \n",
    "        super(SiameseClassifier, self).__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=self.hparams.dropout_prob)\n",
    "\n",
    "        self.input_linear = nn.Linear(self.hparams.latent_dim,\n",
    "                                      self.hparams.inter_dim)\n",
    "\n",
    "        self.output_linear = nn.Linear(self.hparams.inter_dim,\n",
    "                                       self.hparams.output_dim)\n",
    "\n",
    "\n",
    "        # Freeze Pretrain encoder\n",
    "        #if self.hparams.freeze_encoder:\n",
    "        #    autoencoder_thermal.freeze()\n",
    "        #    autoencoder_base.freeze()\n",
    "            \n",
    "        self.encoder_thermal = autoencoder_thermal.encoder\n",
    "        self.encoder_base = autoencoder_base.encoder\n",
    "        self.encoder_noissue = autoencoder_noissue.encoder\n",
    "        \n",
    "\n",
    "        # loss function\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get embeddings\n",
    "        embeddings_thermal = self.encoder_thermal(x)\n",
    "        embeddings_base = self.encoder_base(x)\n",
    "        embeddings_noissue = self.encoder_noissue(x)\n",
    "        \n",
    "        #concat embeddings\n",
    "        embeddings = torch.cat([embeddings_base, embeddings_thermal,embeddings_noissue], dim=1)\n",
    "        #classifier\n",
    "        x = torch.relu((self.dropout(self.input_linear(embeddings))))\n",
    "        x = torch.sigmoid((self.output_linear(x)))\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(),\n",
    "                                 lr=self.hparams.lr,\n",
    "                                 weight_decay=self.hparams.weight_decay)\n",
    "    \n",
    "    def metrics_logger_custom(self, predictions, targets, prefix):\n",
    "        prefix = prefix + '/'\n",
    "        outputs = dict()\n",
    "        for idx, l in enumerate(self.hparams.name_labels_logger):\n",
    "            preds = predictions[:, idx]\n",
    "            target = targets[:, idx].int()\n",
    "            outputs[prefix + l + '/accuracy'] = torchmetrics.functional.accuracy(preds, target)\n",
    "            outputs[prefix + l + '/precision'] = torchmetrics.functional.precision(preds, target)\n",
    "            outputs[prefix + l + '/recall'] = torchmetrics.functional.recall(preds, target)\n",
    "            outputs[prefix + l + '/f1'] = torchmetrics.functional.f1(preds, target)\n",
    "        return outputs\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input, labels  = batch\n",
    "        predictions = self(input)\n",
    "        loss = self.criterion(predictions, labels)\n",
    "        outputs = self.metrics_logger_custom(predictions, labels, 'train')\n",
    "        self.log('train/loss_step', loss)\n",
    "        return {'loss': loss, 'metrics': outputs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        for _, metric in enumerate(outputs[0]['metrics'].keys()):\n",
    "            self.log(metric, torch.tensor([x['metrics'][metric] for x in outputs]).mean())\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input, labels = batch\n",
    "        predictions = self(input)\n",
    "        loss = self.criterion(predictions, labels)\n",
    "        outputs = self.metrics_logger_custom(predictions, labels, 'val')\n",
    "        outputs['val/loss'] = loss\n",
    "        return outputs\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        for _, metric in enumerate(outputs[0].keys()):\n",
    "            self.log(metric, torch.tensor([x[metric] for x in outputs]).mean())\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input, labels = batch\n",
    "        predictions = self(input)\n",
    "        outputs = self.metrics_logger_custom(predictions, labels, 'test')\n",
    "        return outputs\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        for _, metric in enumerate(outputs[0].keys()):\n",
    "            self.log(metric, torch.tensor([x[metric] for x in outputs]).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69693bab-8e3c-4592-b90d-2756baea860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfelipevilla\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">siamese_classifer_v4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/felipevilla/siamese_classifer\" target=\"_blank\">https://wandb.ai/felipevilla/siamese_classifer</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/felipevilla/siamese_classifer/runs/1a3a2wjv\" target=\"_blank\">https://wandb.ai/felipevilla/siamese_classifer/runs/1a3a2wjv</a><br/>\n",
       "                Run data is saved locally in <code>/Users/luisfelipevillaarenas/Documents/T-con/Projects/predictive_care/cpe-replacement/wandb/run-20210920_104025-1a3a2wjv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type        | Params\n",
      "------------------------------------------------\n",
      "0 | dropout         | Dropout     | 0     \n",
      "1 | input_linear    | Linear      | 48.1 K\n",
      "2 | output_linear   | Linear      | 65    \n",
      "3 | encoder_thermal | ConvEncoder | 2.1 M \n",
      "4 | encoder_base    | ConvEncoder | 2.1 M \n",
      "5 | encoder_noissue | ConvEncoder | 2.1 M \n",
      "6 | criterion       | BCELoss     | 0     \n",
      "------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "4.1 M     Non-trainable params\n",
      "6.2 M     Total params\n",
      "24.806    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|█████████ | 102/113 [09:52<01:03,  5.81s/it, loss=0.207, v_num=2wjv]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 104/113 [09:54<00:51,  5.72s/it, loss=0.207, v_num=2wjv]\n",
      "Validating:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 106/113 [09:57<00:39,  5.64s/it, loss=0.207, v_num=2wjv]\n",
      "Validating:  36%|███▋      | 4/11 [00:06<00:11,  1.60s/it]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 108/113 [10:00<00:27,  5.56s/it, loss=0.207, v_num=2wjv]\n",
      "Validating:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 110/113 [10:03<00:16,  5.49s/it, loss=0.207, v_num=2wjv]\n",
      "Validating:  73%|███████▎  | 8/11 [00:12<00:04,  1.53s/it]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 112/113 [10:06<00:05,  5.42s/it, loss=0.207, v_num=2wjv]\n",
      "Validating:  91%|█████████ | 10/11 [00:15<00:01,  1.52s/it]\u001b[A\n",
      "Epoch 0: 100%|██████████| 113/113 [10:09<00:00,  5.39s/it, loss=0.207, v_num=2wjv]\n",
      "Epoch 1:  90%|█████████ | 102/113 [08:08<00:52,  4.79s/it, loss=0.187, v_num=2wjv]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 104/113 [08:10<00:42,  4.72s/it, loss=0.187, v_num=2wjv]\n",
      "Validating:  18%|█▊        | 2/11 [00:02<00:13,  1.47s/it]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 106/113 [08:15<00:32,  4.67s/it, loss=0.187, v_num=2wjv]\n",
      "Validating:  36%|███▋      | 4/11 [00:08<00:16,  2.34s/it]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 108/113 [08:19<00:23,  4.63s/it, loss=0.187, v_num=2wjv]\n",
      "Validating:  55%|█████▍    | 6/11 [00:12<00:11,  2.23s/it]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 110/113 [08:23<00:13,  4.58s/it, loss=0.187, v_num=2wjv]\n",
      "Validating:  73%|███████▎  | 8/11 [00:16<00:06,  2.09s/it]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 112/113 [08:27<00:04,  4.53s/it, loss=0.187, v_num=2wjv]\n",
      "Validating:  91%|█████████ | 10/11 [00:20<00:01,  1.99s/it]\u001b[A\n",
      "Epoch 1: 100%|██████████| 113/113 [08:30<00:00,  4.52s/it, loss=0.187, v_num=2wjv]\n",
      "Epoch 2:  91%|█████████ | 103/113 [05:41<00:33,  3.31s/it, loss=0.167, v_num=2wjv]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 104/113 [05:43<00:29,  3.31s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2:  93%|█████████▎| 105/113 [05:45<00:26,  3.29s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2:  94%|█████████▍| 106/113 [05:47<00:22,  3.28s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2:  95%|█████████▍| 107/113 [05:48<00:19,  3.26s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2:  96%|█████████▌| 108/113 [05:50<00:16,  3.25s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2:  96%|█████████▋| 109/113 [05:52<00:12,  3.23s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2:  97%|█████████▋| 110/113 [05:54<00:09,  3.22s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2:  98%|█████████▊| 111/113 [05:55<00:06,  3.20s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2:  99%|█████████▉| 112/113 [05:56<00:03,  3.18s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2: 100%|██████████| 113/113 [05:57<00:00,  3.17s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 2: 100%|██████████| 113/113 [05:58<00:00,  3.18s/it, loss=0.167, v_num=2wjv]\n",
      "Epoch 3:  90%|█████████ | 102/113 [06:57<00:44,  4.09s/it, loss=0.162, v_num=2wjv]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 104/113 [06:58<00:36,  4.02s/it, loss=0.162, v_num=2wjv]\n",
      "Validating:  18%|█▊        | 2/11 [00:02<00:11,  1.30s/it]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 106/113 [07:01<00:27,  3.97s/it, loss=0.162, v_num=2wjv]\n",
      "Validating:  36%|███▋      | 4/11 [00:04<00:08,  1.17s/it]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 108/113 [07:03<00:19,  3.92s/it, loss=0.162, v_num=2wjv]\n",
      "Validating:  55%|█████▍    | 6/11 [00:06<00:05,  1.03s/it]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 110/113 [07:04<00:11,  3.86s/it, loss=0.162, v_num=2wjv]\n",
      "Validating:  73%|███████▎  | 8/11 [00:08<00:02,  1.00it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 112/113 [07:06<00:03,  3.81s/it, loss=0.162, v_num=2wjv]\n",
      "Validating:  91%|█████████ | 10/11 [00:10<00:00,  1.11it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 113/113 [07:08<00:00,  3.79s/it, loss=0.162, v_num=2wjv]\n",
      "Epoch 3: 100%|██████████| 113/113 [07:08<00:00,  3.79s/it, loss=0.162, v_num=2wjv]\n"
     ]
    }
   ],
   "source": [
    "model = SiameseClassifier()\n",
    "\n",
    "wandb_logger = WandbLogger(name='siamese_classifer_v4',project='siamese_classifer')\n",
    "\n",
    "trainer = Trainer(max_epochs=100, logger= wandb_logger, callbacks=[EarlyStopping(monitor=\"val/loss\")])\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51931f22-3552-46ff-9fe4-2b2dc14b80b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
